---
title: Do cookie-free analytics need cookie compliance popups?
date: 2022-06-09
updated: 2025-01-16
tags: ["article", "analytics", "privacy"]
---

import { Image } from 'astro:assets';
import Figure from "../../../components/blog/Figure.astro";
import Aside from "../../../components/blog/Aside.astro";
import CookieImage from "./upgraded-jonathan-taylor-22GUPUuOqkE-unsplash.jpg";

When I recently reworked my personal website, I figured it'd be neat to see how many ~~days~~ ~~weeks~~ months it took between having visitors, just for my own curiosity. At the same time I wanted to avoid ugly cookie banners, since they're an incredible eyesore (for the few users that don't block annoyances with uBlock Origin), and collecting data on visitors comes with all kinds of ethical concerns.

Luckily there's the option of "privacy-aware analytics", a group of analytics solutions that has grained traction in recent years and who _claim_ to do analytics without any of that Big Brother stuff. No tracking of individual users, and more importantly, no cookies to store on end-user devices. As a bonus on top of all that feel-good no-tracking stuff, they also all claim that you don't need cookie banners if you use them.

But... do they _actually_ let you track analytics without asking your users first? I was a bit skeptical. As just some dude with with no legal background but with way too much time on my hands, I figured I'd be as good as any to dive into EU laws on "cookie banners".

## Technical background

There's been an increasing focus in recent years on how our data is handled when we browse the web. This comes in the wake of the massively privacy-invading tracking done by companies like Google and Facebook becoming public knowledge, of EU legislation forcing companies to get informed consent before processing our data, and of better privacy tools becoming easily available in our browsers.

This has driven a heightened demand for "privacy-aware analytics", a term reserved for analytic solutions that aim to anonymize the collected data enough that it is no longer considered private data. An early example is [Fathom](https://usefathom.com/), but other (more or less) self-hosted solutions like [Plausible](https://plausible.io/), [Ackee](https://ackee.electerious.com/), and [Counter](https://counter.dev/) have also started popping up. They all share the goal of not tracking individual users, while still gathering useful insights into how visitors interact with a website.

Privacy-aware analytics are faced with an obstacle: most analytics requires some way to recognize repeat visitors. Since HTTP is stateless, you can't know if a user has visited before (to count unique visitors) or whether they've visited another page before (to calculate bounce rate) without somehow tracking them. You need a way to identify that the user asking for your `/about` page is the same user that just previously asked for your `/home` page.

Traditionally this has been done by storing a small token on the user's device which their browser then attaches to future requests: a cookie. The analytics backend can then compare that to a list of previously seen tokens, and thereby know whether the user is new or has visited before.

import ClassicAnalyticsDiagram from "./classic-analytics.svg?raw";

<Figure>
  <Fragment set:html={ClassicAnalyticsDiagram} />
  <figcaption class="right">Classic analytics solutions usually use a cookie to check if a request comes from a previously seen user. This is needed for statistics like bounce rates and number of unique visitors.</figcaption>
</Figure>

Cookie-free analytics work slightly differently: instead of storing a small token on the user's device, the backend instead calculates a unique token when the request comes in based on the user's available data.

import NewAnalyticsDiagram from "./new-analytics.svg?raw";

<Figure>
  <Fragment set:html={NewAnalyticsDiagram} />
  <figcaption class="right">Privacy-aware analytics instead calculate some kind of persistent fingerprint for the user, usually based on their IP, User-Agent, and a rotating salt. The fingerprint is usually designed to minimize information disclosure, while still allowing the analytics to check if a user has been seen previously.</figcaption>
</Figure>

This process, known as [fingerprinting](https://amiunique.org/), allows the analytics solution to skirt any legislation that limits when data can be stored on a user's device.

While fingerprinting has a bit of a bad reputation, this implementation can be genuinely designed to respect user privacy. This is done by ensuring that the generated fingerprint can't be correlated back to the individual user, and by quickly binning the collected analytics into things like _"number of unique visitors"_ or _"total bounce rate"_, instead of storing data on how a specific hash interacted with the site (for more information see [Fathom's great explainer](https://usefathom.com/blog/anonymization) on their algorithm).

Since this variant doesn't store anything on the end-user device, a common misconception is that using them means we don't have to ask users for consent. To work out whether that's true, we'll have to look at why we ask for consent in the first place.

## A bit of legal background

_Note: I am not a lawyer. The following is my simplistic understanding of the relevant legislation. Do not use it as legal advice._

When we're talking about analytics there are primarily two different EU laws we'll need to cover: the big baddie, GDPR, and the older cookie law, the ePrivacy Directive. These two both relate to data privacy and are often confused, so here's a quick breakdown:

<dl>
<dt>[GDPR [Regulation (EU) 2016/679]](https://eur-lex.europa.eu/eli/reg/2016/679/oj)</dt>
<dd>Regulation adopted in 2016, came into force in 2018.<br/>Huge law primarily addressing the right of an individual to control their <em>personal data</em>. Trivial examples include names, birthdays, and emails; more complicated examples include browsing history, timestamps, and preferences. If there is any theoretical way that data can be traced back to a person, that data is probably covered by GDPR.<br/>GDPR is a huge beast and one that I am far from competent enough to cover. I will be assuming that the analytics solution you're looking to implement already strongly anonymizes all data, and therefore won't cover GDPR further.</dd>
<dt>[ePrivacy Directive [Directive 2002/58/EC]](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32002L0058)</dt>
<dd>Directive from 2002, later amended in 2009.<br/>One of the early attempts at legislating online privacy. Puts rather strict limits on what data can be <em>retrieved or processed</em> without requiring informed consent from the user. This is regardless of whether the data is personal or not.<br/>Note that this is a directive, not a regulation, meaning it is up to the individual EU countries to implement the directive into law. We'll arbitrarily ignore this distinction, and I will only be considering the wording of the directive itself in this article.</dd>
</dl>

We'll be focusing our efforts on the ePrivacy Directive, since (I believe) the consent required by GDPR can be largely skirted around by anonymizing data properly.

## Legal analysis
_Note: I still ain't no lawyer. Do not use the below as legal advice._

<Aside>
  The concept of "consent" in the ePD has been superseded by that in the GDPR. The exact definition is worked through in [EDPB Opinion 5/2019](https://www.edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_202005_consent_en.pdf), but it can summarized as needing _active_ and _informed_ consent from the user. This is what "cookie banners" aim to do.
</Aside>

In the ePrivacy Directive, there are (at least) two different articles that require consent in a way that is relevant to our use case: Article 5, which requires consent to process/store/retrieve _any_ data on end-user devices, and Article 6, which requires consent to process traffic data for non-traffic purposes.

### Article 5

[Article 5(3) of the ePrivacy Directive](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:02002L0058-20091219#tocId7) says:

> **Article 5(3).** Member States shall ensure that the storing of information, or the gaining of access to information already stored, in the terminal equipment of a subscriber or user is only allowed on condition that the subscriber or user concerned has given his or her consent [...] This shall not prevent any technical storage or access [...] as strictly necessary in order for [a web service provider] explicitly requested by the subscriber or user to provide the service.

<Aside>
  Site owners might argue that analytics are "strictly necessary" to deliver their website, so consent requirement shouldn't apply. This exact argument is addressed by [an opinion on exemptions](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2012/wp194_en.pdf) released by the EU Data Protection Working Party in 2012 (the opinion is worth a read in its entirety, if you're interested in the topic):

  > While [cookie-based analytics] are often considered as a 'strictly necessary' tool for website operators, they are not strictly necessary to provide a functionality explicitly requested by the user [...]. As a consequence, these cookies do not fall under the [exemptions]
</Aside>

Paraphrased in slightly less legalese, this is saying that we must ask the user before accessing or storing any information in their "terminal equipment" (unless that is strictly necessary in order to deliver the service the user has requested).

That's a difficult thing to work with: what does "storing or gain access information" mean? Obviously storing cookies on the end-user's machine falls under that umbrella, but what about things like

- executing JavaScript in the browser to read the screen size, or
- reading the `User-Agent` HTTP header (which starts as a string stored in the user's browser, but is sent to us whenever they make an HTTP request), or
- even parsing the source IP address of the connection they're making to our server?

Luckily the EU Data Protection Working Party has been very good about writing opinions. There's one from [2012 on exemptions](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2012/wp194_en.pdf) and one from [2014 on fingerprinting](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp224_en.pdf). In 2024 (after this article was originally published) the EU Data Protection Board also released a [guideline](https://www.edpb.europa.eu/system/files/2024-10/edpb_guidelines_202302_technical_scope_art_53_eprivacydirective_v2_en_0.pdf) on the technical scope of the ePD (if you only have time to read one, pick this last one). Let's have a look:

- **Screen size, browser version and other client data:** as put by the EU Data Protection Working Party in [a 2014 opinion on fingerprinting](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp224_en.pdf):

  > Information that is stored by one party (including information stored by the user or device manufacturer) which is later accessed by another party is therefore within the scope of Article 5(3). [...]

  Later in the same opinion they mention screen size as "information stored on the user's device":

  > Accessing device information such as the screen size can be useful to optimise the layout of content. [...] Where a third-party requests access to information stored on the user's device for the sole purpose of adapting the content to the characteristics of the device, [a specific exemption applies]

  Apparently accessing anything on the end-user device, even something as hardware-centric as screen size, is covered.

- **User-Agent, Referer, and other HTTP headers:** the specific HTTP headers aren't addressed in any opinion that I could find, but would presumably be covered under the same umbrella as accessing cookies, even if those cookies are set by someone else; it's just under a different header name, and the ones setting the header values are browser vendors. Indeed, as put in the [2024 guideline](https://www.edpb.europa.eu/system/files/2024-10/edpb_guidelines_202302_technical_scope_art_53_eprivacydirective_v2_en_0.pdf):

  > In some cases, the entity instructing the terminal equipment to send back the targeted data and the entity receiving information might not be the same. [...] Instructing the device to send already stored information (for example, through the use of a protocol, or an SDK that imply the proactive sending of information by the terminal equipment) makes an intrusion into the terminal equipment possible, therefore such an access triggers the applicability of Article 5(3).) ePD.

  If an agreed upon protocol (in this case the [RFC 9110 specification](https://www.rfc-editor.org/rfc/rfc9110#field.user-agent)) instructs the equipment to send data, then accessing that data is covered.

---

For fingerprint-based analytics, this is a lot less of a hurdle though. By using fingerprints based on data that's already delivered by the user device, such as IP addresses and `User-Agent` identifiers, one can sneakily avoid Article 5(3).

The more concerning article in that context is [Article 6](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:02002L0058-20091219#tocId8):

<Aside>"Traffic data" is defined by the ePD as "any data processed for the purpose of the conveyance of a communication on an electronic communications network or for the billing thereof"</Aside>

> **Article 6(3).** For the purpose of marketing electronic communications services or for the provision of value added services, the provider [...] may process [traffic data] to the extent and for the duration necessary for such services or marketing, if the subscriber or user to whom the data relate has given his or her prior consent.
> 
> **Article 6(4).** The service provider must inform the subscriber or user of the types of traffic data which are processed and of the duration of such processing for the purposes mentioned in paragraph 2 and, prior to obtaining consent, for the purposes mentioned in paragraph 3.
> 
> <Aside>"Value added service" is defined as "any service which requires the processing of traffic data or location data other than traffic data beyond what is necessary for the transmission of a communication or the billing thereof</Aside>**Article 6(5).**  Processing of traffic data [...] must be restricted to persons acting under the authority of providers [...] handling billing or traffic management, customer enquiries, fraud detection, marketing electronic communications services or providing a value added service, and must be restricted to what is necessary for the purposes of such activities.

<Aside>
**Update:** In 2023 the EDPB released [an opinion](https://www.edpb.europa.eu/system/files/2023-11/edpb_guidelines_202302_technical_scope_art_53_eprivacydirective_en.pdf) on the applicability of Article 5(3) in various technical situations, including for IP-only tracking. They conclude that:

> **54.** [In the context of IP-only tracking] Article 5(3) ePD could apply even though the instruction to make the IP
available has been made by a different entity than the receiving one.  
> **55.** [...] the static outbound IPv4 originating from a user's router would fall within that case, as well as IPV6 addresses [...]. Unless the entity can ensure that the IP address does not originate from the terminal equipment of a user or subscriber, it has to take all the steps pursuant to the Article 5(3) ePD

This supports my prior analysis, ruling out processing user IPs without asking for consent.
</Aside>

This is a bit of a bigger blocker for fingerprint-based analytics. Without processing traffic data, which IP addresses presumably fall under, it gets a whole lot harder to fingerprint individual users.

Site owners might argue that they fall under one of the permitted use cases, but for my use case that didn't seem to be the case: analytics isn't billing or traffic management, nor is it handling customer enquiries. _Some_ analytics probably fall under the fraud detection umbrella, but the simplistic analytics I'm interested in certainly don't. The last two permitted use cases, marketing our web services and "providing a value added service", require user consent anyway -- so even though we can argue to fall into one of those two, they aren't of much help in avoiding "cookie banners".

---

It's also worth noting that the directive doesn't have any exceptions for anonymized data. As put by the EU Data Protection Working Party in [a 2014 opinion on anonymization](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf):

> First, anonymisation is a technique applied to personal data in order to achieve irreversible de-identification. Therefore, the starting assumption is that the personal data must have been collected and processed in compliance with the applicable legislation on the retention of data in an identifiable format.

Not only can we not read user data from users without asking them nicely first, those buggers in the EU Data Protection Working Party don't even let us claim that our ethical high ground of anonymization makes us exempt.

## What data is covered by the ePrivacy Directive?

Let's have a look at the various data points we can use to identify repeat visits, and what the ePrivacy Directive says about them:

### IP address or other traffic data

Covered by the Directive in Article 6, as mentioned in the previous section.

Since things like GeoIP lookups use the IP address and therefore require processing it first, using a user's country or city would also require consent.

### Screen size, browser version and other client data

Most likely covered by the Directive as data that has previously been stored by the browser vendor or device manufacturer, which we then process. As put by the EU Data Protection Working Party in [a 2014 opinion on fingerprinting](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp224_en.pdf):

> Information that is stored by one party (including information stored by the user or device manufacturer) which is later accessed by another party is therefore within the scope of Article 5(3). [...] The consent requirement also applies when a read-only value is accessed (e.g. requesting the MAC address of a network interface via the OS API).

In the same opinion, they also briefly mention the act of fingerprinting using HTTP headers, using the `User-Agent` header as an example, but do not specifically mention it as requiring informed consent.

### User-Agent, Referer, and other HTTP headers

These might actually be possible to use without any consent requirements. It could be argued that reading these headers isn't gaining access to data stored on the user's terminal equipment, since they're automatically sent by the user's device to the server. It could further be argued that they aren't traffic data. For example, the [RFC 9110 specification](https://www.rfc-editor.org/rfc/rfc9110#field.user-agent) describes the `User-Agent` header as follows:

> The "User-Agent" header field contains information about the user agent originating the request, which is often used by servers to help identify the scope of reported interoperability problems, to work around or tailor responses to avoid particular user agent limitations, and for analytics regarding browser or operating system use.

<Aside>
**Update:** HTTP headers including `User-Agent` are briefly noted in [the recent 2023 EDPB opinion](https://www.edpb.europa.eu/system/files/2023-11/edpb_guidelines_202302_technical_scope_art_53_eprivacydirective_en.pdf):

> The application protocol can include several mechanisms to provide context data (such as HTTP header including 'accept' field or user agent) [...]. Once again, the abuse of those mechanisms (for example in the context of fingerprinting or the tracking of resource identifiers) can lead to the application of Article 5(3) ePD.

This seems to imply that HTTP headers cannot be used without consent either.
</Aside>

This seems to specifically describe it as being sent for non-traffic purposes.

If those two arguments -- HTTP headers being neither on-device nor traffic data -- hold up in court, then HTTP headers might actually be available to us!

The only official opinion I could find from the EU Data Protection Working Party is [the 2014 opinion on fingerprinting](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp224_en.pdf), which doesn't conclude one way or the other about whether HTTP headers are covered by the ePD consent requirements.

---

All in all, it looks like the ePD leaves us with very few data points left to use for fingerprinting without asking the user for informed consent. While this is certainly a win for privacy when it comes to companies that are interested in finding loopholes, it does extinguish any hope we have of escaping the popup nightmare the web has become today.

## Technical analysis

If we look at [the algorithm used by Fathom](https://usefathom.com/blog/anonymization), we see that it collects the following information for fingerprinting: IP address, `User-Agent`, site hostname, and site ID (plus the referrer, which they apparently failed to mention, but which appears in their demo dashboard).

As we saw above, the IP address is considered traffic data which is explicitly covered by the ePrivacy Directive, and therefore require user consent to access. This means that even if we use Fathom analytics, despite its cookie-free and privacy-friendly design, we'll _still_ need a cookie banner to get user consent.

---

<Aside>**Update:** [I asked](https://github.com/plausible/analytics/discussions/1963) the team behind Plausible for their opinion on this analysis. While very forthcoming, their response was essentially "our legal team has checked our claims". Elaboration would have been nice, but I certainly don't blame them for trusting a legal team over some weirdo on the internet.</Aside>

A similar story is true for [Plausible's algorithm](https://plausible.io/data-policy). It collects the following information: IP address, `User-Agent`, page URL, and referrer. Again the IP address requires consent according to the ePrivacy Directive, so we are in exactly the same boat as with Fathom: privacy-aware and cookie-free or not, a cookie popup is legally required. Even the people behind Plausible seem to be confused here, using (at the time of this writing) "No need for cookie banners or GDPR consent" as one of the titles on their landing page.

Every other privacy-aware analytics solution I've found, including [Ackee](https://github.com/electerious/Ackee/blob/master/docs/Anonymization.md) and [Counter](https://github.com/ihucos/counter.dev#how-can-it-be-free), also uses data covered by the ePrivacy Directive.

## Exemptions

Just because we cannot _track_ users using any sort of data without consent doesn't mean we need consent to use cookies. As put by Article 5(3) of the ePD: 

> [the restrictions] shall not prevent any technical storage or access for the sole purpose of carrying out the transmission of a communication over an electronic communications network, or as strictly necessary in order for the provider of an information society service explicitly requested by the subscriber or user to provide the service.

You won't have to worry about any huge EU fines just because you're using cookies to track login state, to store shopping cart items between HTTP requests, or to implement sticky sessions in your load balancer. Just be sure to actually use them for that purpose -- trying to be tricky by using a login session cookie for analytics would throw you right back into non-compliance.

If you are interested in a more in-depth analysis of when these exemptions apply, the EU Data Protection Working Party released [an opinion on exemptions](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2012/wp194_en.pdf) in 2012 (with examples) where they delve deeper into it. I can highly recommend reading it.

## Conclusion

Although it might come as a surprise (it certainly did for me), privacy-aware and cookie-free analytics aren't going to save us from cookie banners with the way the legislation is currently written. If you are interested in avoiding cookie popups on your website, you'll have to make do with the very basic analytics that don't require knowing whether you've seen a user before -- making them essentially useless.

Or do without. That's what I ended up doing.
